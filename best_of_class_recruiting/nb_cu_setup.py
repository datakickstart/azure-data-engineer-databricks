# Databricks notebook source
# MAGIC %run ../utils/mount_storage

# COMMAND ----------

curated_base_path = dbutils.secrets.get("demo", "refined-datalake-path") + "cu_curated"
curated_format = "delta"

adls_authenticate()

# COMMAND ----------

def create_database(db_name, path, drop=False):
    if drop:
        spark.sql(f"DROP DATABASE IF EXISTS {db_name} CASCADE;")    
    spark.sql(f"CREATE DATABASE IF NOT EXISTS {db_name} LOCATION '{path}'")

create_database("curated", curated_base_path, False)

# COMMAND ----------

# MAGIC %sql
# MAGIC DESCRIBE FORMATTED curated.dim_area;

# COMMAND ----------

# MAGIC %sql
# MAGIC CREATE TABLE curated.dim_area (
# MAGIC dim_area_id bigint GENERATED BY DEFAULT AS IDENTITY,
# MAGIC area_code string,
# MAGIC area_name string,
# MAGIC display_level bigint,
# MAGIC is_deleted boolean,
# MAGIC last_modified timestamp
# MAGIC )

# COMMAND ----------


